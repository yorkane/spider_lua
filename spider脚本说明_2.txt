lua脚本爬虫说明
一：lua脚本固定方法
1：getLastPublishTime() 
	取得对方网站最后发布时间 返回yyyy-MM-dd HH:mm:ss格式时间
2：downloadAndParseListPage(pageno) 
    下载分析列表页,返回列表对象数组
3：downloadDetailPage(tab) 
	下载三级页内容，返回要保存的数据对象
	
二：go暴露基本方法
1：download("href",head)
	普通下载，href：下载的链接地址，head：请求头（大部分网站不需要传）
	返回下载内容：字符串，调用样例如下
	download("http://www.ccgp.gov.cn",{})
	download("http://www.baidu.com",{["Host"]="gsxt.lngs.gov.cn"})
	扩展：download(true,"href",head)true支持https安全协议，默认不支持
2：downloadAdv(href,method,param,head,cookies)
	高级下载，返回下载内容字符串和cookise字符串，调用样例如下
	content,cookies= downloadAdv("http://gsxt.lngs.gov.cn/saicpub/entPublicitySC/entPublicityDC/getJbxxAction.action","get",{},{},"")
	主要用于需要cookies的网站
	扩展：downloadAdv(true,href,method,param,head,cookies)true支持https安全协议，默认不支持

三：go暴露jquery方法
1：findOneText
	样例：findOneText("ul li a:eq(0)","<ur><li><a>1</a></li><li><a>2</a></li></ur>")
	扩展：findOneText("style,script","div.divtest","<div class='divtest'><style>ssss</style><script>alert(1)</script>去除style,script标签</div>")
2：findOneHtml
	样例： findOneHtml("ul li:eq(0)","<ur><li><a>1</a></li><li><a>2</a></li></ur>")
	扩展： findOneHtml("style","div.divtest","<div class='divtest'><style>ssss</style>去除style标签</div>")
3：findListText
	样例： findListText("ul li","<ur><li><a>1</a></li><li><a>2</a></li></ur>")
4：findListHtml
	样例： findListHtml("ul li","<ur><li><a>1</a></li><li><a>2</a></li></ur>")
5：findMap
样例：
	item={}
	item["href"]="a:eq(0):attr(href)"
	item["title"]="a:eq(0):attr(title)"
	findMap(item,"<ur><li><a href='www.qq.com' title="qq">1</a></li><li><a>2</a></li></ur>")

四：go暴露其他方法
1：changeDownloader() 指定某个下载器
2：timeSleep(60)延时,单位秒
3：transCode("unicode","内容")，支持unicode解码,urlencode_gbk编码,urlencode_utf8编码,urldecode_utf8解码,decode64解码
4：findHasExit("bidding","{'href':'www.baidu.com'}") 判断信息是否存在，true存在、false
5：getEcpsCode("bj",content)公示类，获取验证码，返回处理后的结果
6: unGzip() gzip解压
7: getEntNames() 公示类，获取企业名录，返回table
8：saveErrLog(爬虫代码, 爬虫名称, url地址, 错误信息) 保存错误日志
五：常用公用方法
local com=require "res.util.comm"
1：parseDate("2015.12.12 14:25:36","yyyyMMddHHmm")
	返回统一格式：2015-12-12 14:25:36
2：strToTimestamp("2015-12-12 14:25:36")
	返回publishtime时间戳
3：checkData(tab1,tab2)
	验证数据是否有空值
4：printf(tab)
	迭代打印tab
5：encodeURI，decodeURI
	URL编码，解码
6：json,table转换
local json=require "res.util.json"
	table 转 json
	local tab = { one='first',two='second',three={2,3,5}}
	jsonstr = json.encode(tab)
	json 转 table
	local tab = json.decode(jsonstr)
其他详见comm.lua,json.lua
 

六：其他说明
1：download、downloadAdv中href参数如果含有图片格式，方法会下载base64的图片字符
	如：img=download("http://www.myimg.info/1.png",{})
2: 命名规则
	爬虫代码：区域_网站代码_栏目代码
	脚本名称：spider_区域_网站代码_栏目代码.lua
七：注意事项
①数据入库前要验证
--验证示例：
local checkAttr={"title","href","publishtime","detail","contenthtml"}
local b,err=com.checkData(checkAttr,data)

②针对列表页没有时分秒的情况，lua脚本定义临时变量判重
--下载分析列表页示例：
local lastRoundTagId = ""--上次标识
local currRoundTagId = ""--当前标识
local firstStart = true--是否首次开始任务
function downloadAndParseListPage(pageno)
	local page={}	
	local href=spiderTargetChannelUrl.."?pageNo="..tostring(pageno)
	local content = download(href,{})
	local list = findListHtml(".newslist_media",content)
	for k,v in pairs(list) do
		local item = {}
		item["title"]=com.trim(findOneText(".media-heading a",v))
		item["href"]=findOneText(".media-body a:attr(href)",v)
		item["publishtime"]=findOneText(".media-body p:eq(1)",v)
		item["publishtime"]=com.parseDate(item["publishtime"],"yyyyMMdd")
		if k==1 and pageno==1 then
			if lastRoundTagId=="" then
				lastRoundTagId=item["href"]
			else
				firstStart=false
			end	
			currRoundTagId=item["href"]
		end
		if lastRoundTagId==item["href"] and not firstStart then
			lastRoundTagId=currRoundTagId	
			item["exit"]="true"
		end
		table.insert(page,item)

	end
	return page
end
③迭代请求防止死循环
--下载分析列表页
local trylistnum=0
function downloadAndParseListPage(pageno)
	local list={}
	while trylistnum<5 and table.getn(list)<1 do
		trylistnum=trylistnum+1
		print(spiderCode,"两分钟后重新获取列表")
		timeSleep(120)--两分钟后重新获取列表
		return downloadAndParseListPage(pageno)
	end
	trylistnum=0
	return list
end